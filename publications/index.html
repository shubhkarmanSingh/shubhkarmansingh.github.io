<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>research | Shubhkarman Singh</title> <meta name="author" content="Shubhkarman Singh"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shubhkarmansingh.github.io/publications/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Shubhkarman </span>Singh</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">research<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">research</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="bibliography">Journal Articles</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <img src="/assets/img/publication_preview/equityeducation.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="equityeducation.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="RESPECT" class="col-sm-8"> <div class="title">Empowering Families to Support their Child’s Education: A Pilot Program</div> <div class="author"> Shubhkarman Singh</div> <div class="periodical"> <em>RESPECT</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/THESIS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This thesis delves into the multifaceted landscape of computer science education within underprivi- leged and underrepresented communities, focusing on its impact on students’ journey towards higher education. Grounded in the principles of cultural capital and asset-based teaching methodologies, this research endeavors to address the barriers confronting students by offering tailored workshops. These workshops provide a scaffolded framework that empowers students and families to navigate educational opportunities, financial aid, mental health, and more. The thesis explores the significance of cultural capital in shaping students’ academic trajectories and advocates for an approach that ac- knowledges and leverages the diverse strengths within these communities. By integrating culturally relevant content, collaborative curriculum design, and dynamic teaching methods, the workshops aim to foster inclusivity and empowerment. The culmination of this effort reflects a commitment to cre- ating an educational landscape characterized by equity, unity, and transformative growth.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <img src="/assets/img/publication_preview/afib.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="afib.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ICML" class="col-sm-8"> <div class="title">Empowering Families to Support their Child’s Education: A Pilot Program</div> <div class="author"> Shubhkarman Singh, Zeynep Toprakbasti, Nawaf Osman, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Kasper Lindberg, Eyad Alsilimy' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>ICML</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/A_Fib_XAI_Paper.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Currently, there are many ML models that, given a patient’s ECG, can diagnose whether that patient has AFib with high accuracy. The issue with many of these models is that they are black- box models which make it difficult for community healthcare workers to interpret their decisions. Our solution is AFib-XAI, a program that uses explainable AI methods to display the important data points and regions of interest in an ECG that were factored into a model’s AFib diagnosis, as well as generate accurate, human-readable explanations for that model’s diagnosis. AFib-XAI can be run through a command-line interface. The program offers a selection of 3 AFib diagnostic deep learning models and 4 SHAP-based explainability methods. The user must provide an ECG, make a model se- lection, and select an explainability method. Af- terward, the program will be run. Once the program has finished running, the user will be given a visual result from the SHAP explainability method, as well as a very basic text explanation generated from the results.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">report</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <img src="/assets/img/publication_preview/nasa_logo.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="nasa_logo.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="nasa" class="col-sm-8"> <div class="title">NASA SUITS Challenge with UW Reality Labs and AstroHuskies</div> <div class="author"> Shubhkarman Singh, Adrian Dinh, Marcus Christerson, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Muskan Bawa' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> UW CSE Capstone Demo Day, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://uwrealitylab.github.io/xrcapstone23wi-team2/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> <a href="https://realitylab.uw.edu/staging/?p=974" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">News</a> </div> <div class="abstract hidden"> <p>To support astronauts conducting their essential research and daily tasks, we can leverage computer vision and AR technology to identify geological points of interest, assist in navigation, and present important data using a minimal, non-obtrusive UI.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <img src="/assets/img/publication_preview/seurat.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="seurat.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="comp_bio" class="col-sm-8"> <div class="title">Comparing methods for Single-Cell RNA Sequencing Analysis in the Characterization of mir-190 During Cell Fate Selection</div> <div class="author"> Shubhkarman Singh, and Ariana Nagainis</div> <div class="periodical"> UW CSE Computational Biology Graduate Capstone, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/CSE_527_Computational_Biology-3.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Stem cells are important in the generation of cell diversity. They must ensure a properly-timed cascade of transcription factors that determine cell fate. However, the mechanisms that balance the generation of cellular diversity is poorly understood. To elucidate these mechanisms, the Drosophila melanogaster larval central nervous system (CNS) has become a powerful model. The neuroblasts (NBs) in the larval central nervous system divide asymmetrically and give rise to cells with different developmental fates. Currently, there is little known about whether regulation of cell fate may involve microRNAs (miRNAs). These short non-coding RNA’s silence gene expression of complementary mRNA transcripts. There is a possibility that temporal and spatial regulators at the post transcriptional level have potential to coordinate asymmetry of cell fate determinants. Previous research has used a single-cell RNA sequencing (scRNAseq) to compare the transcriptomics of individual cells between wildtype (wt) and mir-190 KO cells in drosophila. mir-190 deficient cells show a decrease in neuron production and an increase in differentiat- ing cells, glial cells and kenyon cells compared to the control. This data suggests miR-190 plays a role in regulating the balance of glial cells and possibly affects self-renewal pathways. Currently, many scRNAseq publications use Seurat for their anaylsis. Although Seurat is the most popular package, there are a plethora of other scRNAseq packages that differ in their approach and can affect the accuracy and interpretability of the results. Thus our goal for this project is to compare the accuracy of results from different scRNA-seq data analysis methods, such as Seurat, scVI, constrastiveVI, and linearVI. We aim to determine if mir-190 deficient cells remain to show a decrease in neuron production compared to wildtype with newer and improved scRNAseq analysis.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <img src="/assets/img/publication_preview/xai.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="xai.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xai" class="col-sm-8"> <div class="title">Literature Review on the State of Explainable AI in Medicine</div> <div class="author"> Shubhkarman Singh</div> <div class="periodical"> UW CSE AI in Medicine Graduate Capstone, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Final_Paper_red.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/xai_presentation.mov" class="btn btn-sm z-depth-0" role="button">Video</a> </div> <div class="abstract hidden"> <p>Artificial Intelligence and Machine Learning have demonstrated remarkable potential in numerous domains from beating humans at Go to self-driving cars. Most of the recent growth in machine learning has been driven by the widespread use of complex models, like deep neural networks. However, this complexity comes at a cost as these ML systems are black boxes. Users and people being impacted have little to no understanding of how they make predictions. This lack of understanding presents multiple problems with serious consequences, and we need to develop ethical models that are interpretable, tractable, and trustworthy. The use of ML systems is expanding not just in software engineering but into education, law enforcement, and healthcare. In health care, current AI-based systems fail to hold up performance in the real-world clinical environments. Other concerns surrounding the use of ML in medicine include privacy, bias, lack of transparency, and security as well as causality, informativeness, and fairness. AI decisions made or influenced by such systems affect human health, there is an urgent need for understanding of how such decisions are made. A consensus is emerging in favor of explainable AI/ML to highlight how predictions are made, but we need to be wary about explainable AI in its current. In this report, I will highlight four papers that touch on an overview of limits in explainability, the definitions of explainability and how to evaluate them, the importance of extending explainability to causability, an example of explainable AI evaluation on a multi-modal medical imaging task, and how explanation trustworthiness is overlooked.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <img src="/assets/img/publication_preview/nlp.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="nlp.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="nlp" class="col-sm-8"> <div class="title">Reproducibility Report for Self-Supervised Quality Estimation for Machine Translation</div> <div class="author"> Chahyon Ku, Daniel Cheng, Shubhkarman Singh, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Sherry Zhao' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> University of Washington Allen School Research Night, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/CSE_481N-3.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/assets/pdf/cse481n_final_poster_selfsupervisedqe-2.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Fine-tuning pre-trained multilingual BERT on domain-specific parallel data from the open gold-standard parallel corpus will have higher sentence-level spearman-correlation and word-level F1-scores on quality estimation tasks than prior unsupervised methods.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <img src="/assets/img/publication_preview/verbaleyes.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="verbaleyes.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="VerbalEyes" class="col-sm-8"> <div class="title">VerbalEyes: Pioneering AI-generated audio description Investors Pitch</div> <div class="author"> Daniel Zhu, Shubhkarman Singh, Honson Ling, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Arthur Liu, Amy Xu, Alli Hishikawa, Joana Li' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> University of Washington Undergraduate Research Symposium, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/assets/pdf/verbaleyes.mov" class="btn btn-sm z-depth-0" role="button">Slides</a> <a href="https://blog.foster.uw.edu/sweet-16-2021-dempsey-startup/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">News</a> <a href="https://www.youtube.com/watch?v=3fyA2_Q5_Jg" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Interview</a> </div> <div class="abstract hidden"> <p>Every minute, there are 500 hours of user-generated content uploaded to YouTube2. There are billions of hours of video content across major social media platforms like Facebook, Twitter, Snapchat, and Instagram, and television broadcasters create thousands of hours of content for their viewers. Companies across the globe spend billions of dollars on video marketing campaigns and employee training videos. For the 12 million people in the United States who are blind or visually impaired, this enormous amount of engaging content is completely inaccessible. Among the 119 visually impaired individuals who we surveyed and interviewed, there was universal frustration with being unable to enjoy the content that they wished to. Audio description (AD), an additional narration track that conveys essential visual information in a media work, is imperative for improving video accessibility for people who are blind or visually impaired. The trend of providing AD for content is starting to pick up: major streaming services such as Netflix, Disney+, and Apple TV+ have begun offering AD on their new content, and large companies like P&amp;G have started audio describing some marketing videos. However, this increase is slowed by manual audio description processes. Traditional AD vendors charge an expensive $9-15 per video minute with a slow turnaround time for 4-9 business days, all while being unresponsive to customer requests and delivering their services via antiquated and inefficient workflows. While the world is ready for audio description to become as ubiquitous as closed captioning, current systems cannot lead us to an accessible internet.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Shubhkarman Singh. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>