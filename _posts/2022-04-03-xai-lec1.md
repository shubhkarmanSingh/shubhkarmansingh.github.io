---
layout: distill
title: 'RISE: Randomized Input Sampling for Explanation of Black-box Models'
description: Vitali Petsiuk <a href='#'>vpetsiuk@bu.edu</a>, Abir Das <a href='#'>dasabir@bu.edu</a>, Kate Saenko <a href='#'>saenko@bu.edu</a>
tags: distill formatting
giscus_comments: true
date: 2022-04-03
featured: false

authors:
  - name: Shubhkarman Singh
    url: 
    affiliations:
      name: Paul G. Allen School of CSE, University of Washington

bibliography: 2022-04-03-xai-lec1.bib

# Optionally, you can add a table of contents to your post.
# NOTES:
#   - make sure that TOC names match the actual section names
#     for hyperlinks within the post to work correctly.
#   - we may want to automate TOC generation in the future using
#     jekyll-toc plugin (https://github.com/toshimaru/jekyll-toc).
toc:
  - name: Overview
    # if a section has subsections, you can add them as follows:
    # subsections:
    #   - name: Example Child Subsection 1
    #   - name: Example Child Subsection 2
  - name: Methods
  - name: Purpose
  - name: Technical Quality
  - name: Industry Use Cases

# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }

---

## Overview

In this paper, the authors propose an approach called RISE that generates an importance map which indicates how salient each pixel is for the model’s prediction. <d-cite key="DBLP:journals/corr/abs-1806-07421"></d-cite> In contrast to white-box approaches that estimate pixel importance using gradients, RISE works on black-box models. It estimates importance empirically by probing the model with randomly masked versions of the input image and obtaining corresponding outputs. They compare their approach to other importance extraction methods using an automatic deletion/insertion metric and a pointing metric based on human-annotated object segments.

***

## Methods

They measure the importance of an image region by perturbing it and observe the effect on the black box decision. They estimate the importance of pixels by dimming them in random combinations, reducing their intensities down to zero. They first mask the image by preserving only a subset of pixels, then the confidence score for the masked image is computed by the black box. The saliency map is computed as a weighted sum of random masks, where the weights are the probability scores adjusted for the distribution of the random maks. They incorporate bilinear upsampling for mask generation which results in a smooth importance map. 

***

## Purpose

The main question that this paper is asking about a model is looking at how salient each pixel in an image is for the model’s prediction and more specifically if they can do so without using gradients or other internal network state, which would work on black-box models.

***

## Technical Quality

I think this paper is mostly technically sound as it is straightforward to implement and the results in the paper show how capable RISE is in identifying important pixels, particularly in black-box models. There are some concerns that I have though. The pointing game metric detailed in the paper feels a bit arbitrary as using only a single point to determine if an example is considered a hit seems prone to a bunch of noise and falls into the trap described earlier in the paper with using human-centered explanations to describe model decisions. 

***

## Industry Use Cases

The paper mentions the application of RISE with image captioning which relates to a project that did in a startup on video captioning and trying to analyze the video for key frames that describe a particular scene. If I was able to understand what parts of each key frame was important, that might give better insight into more accurate captioning.